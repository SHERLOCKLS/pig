
    首先要考虑用哪种思路来解这个问题。
    乍一看与行人再识别和细粒度分类、检索啥的很像，尤其是很像检索，但是这又是一个分类的问题。
    基本想法是，如果让人类去干这件事，人类会怎么做。肯定是拿着一个测试图片，去和每个视频中的
    每一帧（因为拍摄角度不同）去比对，然后觉得某个视频中的一些帧和这个图片很像（注意，人类可能
    对拍摄角度有一定的鲁棒性，当然也与该角度是否存在有区分度的特征有关，【attention？】）。
    因此，【我们希望学习到这个特征。有可能imagenet特征+attention就可以了？】
    【正是由于拍摄角度的问题，使用普通的分类方法（脸和肚子的差别可能大过不同猪的差别）和
    人脸识别方法（除非把不同角度拿出来单独构建Triplet Loss）都不太行。】
    这里我们构建图片与视频之间的Triplet Loss，即L(video_p, image_p, image_n)，在计算image和video距离时
    取所有帧中距离最小的若干帧进行平均，这样就解决了拍摄角度的问题。
    可见这个赛题和人（猪）脸识别最大的差别就是拍摄角度！那为什么不是re id呢，我认为原因是【人在不同角度
    没有那么大的差别（尤其是考虑到衣服的颜色之类），而猪的正面和侧面差别很大，人类亦无法分辨。】
    
    所以关键可能是【如何解决只在每个视频中与测试图片匹配最好的几帧上计算loss，并进行有效的BP。
    另外不知道数据量是否合适】


    AlignedReID: Surpassing Human-Level Performance in Person Re-Identification
    原文好像是h方向的end-to-end对齐，认猪的话可以推广到h和w两个方向的end-to-end对齐？
    
    